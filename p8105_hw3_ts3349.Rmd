---
title: "p8105_hw3_ts3349"
author: "Tessa Senders"
date: "10/6/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries}
library(tidyverse)
library(p8105.datasets)
library(hexbin)
library(patchwork)
```

## Problem 1


```{r load data prob 1}
data("instacart")
```
This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.  Observations are the level of items in orders by user.  There are user/order variables-user ID, order ID, order day, and order hour.  There are also item variables-name, aisle, department, and some numeric codes.



How many aisles and which are most items from?

```{r prob 1 counting}
aisles_df <- instacart %>%
  count(aisle) %>%
  arrange(desc(n))

head(aisles_df)
```
There are `r nrow(aisles_df)` aisles and the most items are ordered from the fresh vegetables and fresh fruits aisles. 


Plot

```{r prob 1 plot}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

Table

```{r prob 1 table}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()

```

Second Table

```{r prob 1 table 2}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>%
  knitr::kable()

```


## Problem 2


```{r problem 2 bullet 1}
activity_df <- read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_day", 
    values_to = "activity_count"
  ) %>%
  mutate(day = str_to_lower(day)) %>%
  mutate(day_temp = as.numeric(factor(day, levels = str_c(c("saturday", "sunday", "monday", "tuesday", "wednesday", "thursday", "friday"))))) %>%
  mutate(day_of_week = if_else(day_temp == 1 | day_temp == 2, "weekend", "weekday")) %>%
  select(!day_temp)%>%
  mutate(minute_of_day = as.numeric(str_remove(minute_of_day, "activity_"))) %>%
  relocate(week, day_of_week, day, day_id, minute_of_day, activity_count)

head(activity_df)  
```
This data set contains information from a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure.  For each minute of each day for a total of 5 weeks (35 days), his activity count was recorded.  The data set contains `r ncol(activity_df)` variables.  These variables include week(week number 1-5), day_of_week(whether the day was a weekday or weekend day), day(Sunday-Saturday), day_id(1-35), minute_of_day, and activity_count.  There are a total of `r nrow(activity_df)` rows in the final data set.  The median number for activity_count for example is `r median(pull(activity_df, activity_count))`.  


```{r problem 2 bullet 2}
activity_table_df <- activity_df %>% 
  group_by(day_id, week) %>%
  summarize(total_activity = sum(activity_count)) %>%
  relocate(week)

activity_table_df %>%
  knitr::kable()
```
Looking at the data there are a couple clear outliers where the total activity count is below 2000.  Most of the total activity count values for each day are between 130,000 and 700,000.  For the first week most total activity count values were around 300,000.  The second week, most of the total activity count values seem to increase to around 400,000.  Overtime, however, the values become more sporadic dipping to around 150,000 and then increasing to as high as around 600,000.


```{r problem 2 bullet 3}
activity_df  %>% 
  mutate(day = as.factor(day)) %>%
  mutate(day = factor(day, levels = str_c(c("sunday", "monday", "tuesday", "wednesday", "thursday", "friday", "saturday")))) %>%
  ggplot(aes(x = minute_of_day, y = activity_count, color = day)) + 
  geom_line(alpha = 0.5) + 
  labs(
    title = "Activity Over the Course of the Day",
    x = "Minute of the Day",
    y = "Activity Count",
    caption = "Data from the accelerometer data collected on a 63 year-old male with BMI 25"
  ) +
  guides(color = guide_legend("Day"))
```
The first few hundred minutes of the day for all days of the week seem to have the lowest activity counts probably because the man is sleeping.  For most days of the week the activity count seems to spike towards the end of the day around the 1250th minute of the day.  Tuesdays through Thursdays seem to have some of the overall highest activity counts during the 450th minute and the 1200th minute of the day.  Mondays' activity count however typically peaks around the 750th minute of the day.


## Problem 3


```{r load data for prob 3}
data("ny_noaa")
```


```{r problem 3 bullet 1}
ny_noaa_df <- ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into=c("year", "month", "day"), sep = "-") %>%
  mutate(year = as.numeric(year)) %>%
  mutate(month = as.numeric(month)) %>%
  mutate(day = as.numeric(day)) %>%
  mutate(prcp_cm = prcp / 100) %>%
  mutate(snow_cm = snow / 10) %>%
  mutate(snwd_cm = snwd / 10) %>%
  mutate(tmax = as.numeric(tmax) / 10) %>%
  mutate(tmin = as.numeric(tmin) / 10) %>%
  select(-prcp, -snow, -snwd) 

head(ny_noaa_df)
 
ny_noaa_snowfall <- ny_noaa_df %>%
  group_by(snow_cm) %>%
  count() %>%
  arrange(desc(n))

head(ny_noaa_snowfall)


```
0.0 is the most commonly observed snowfall value because it does not snow year round in New York.  Most of the time it is not snowing.  After NA (missing), the next most common snowfall amounts are 2.5cm and 1.3cm.


```{r problem 3 bullet 2}
noaa_jan_july_df <- ny_noaa_df  %>% 
  filter((month == 1) | (month == 7)) %>%
  group_by(id, year, month) %>%
  summarize(avg_max_temp = mean(tmax, na.rm=TRUE))

noaa_jan_july_df %>%
  ggplot(aes(x = year, y = avg_max_temp, color = id)) + 
  geom_line() + 
  facet_grid(. ~ month) +
  labs(
    title = "Average Max Temperature Across Years for January vs July",
    x = "Year",
    y = "Average Max Temperature (C)",
    caption = "Data from the New York NOAA weather stations across years for January and July ") +
    theme(legend.position = "none") +
    theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```
Both graphs show a zigzag pattern where the average max temperature dips a little one year but then increases a little the next year.  There seems to be a very slight upward trend for January but overall the average max temperatures for January seem fairly consistent.  The average max temperature in July seem very consistent overall.  Some stations in both graphs seem to always be slightly higher or slightly lower overall than the others.  In the graph for July there seems to be a station that is an outlier in the late 80s with a large dip in the average max temperature.  In the year 2000 for January there seems to be a station with a much higher average max temperature than the others.  The max temperatures in July are overall higher than the max temperatures in January.


```{r problem 3 bullet 3}
tmax_vs_tmin_plot <- ny_noaa_df %>%
  ggplot(aes(x = tmax, y = tmin)) + 
  geom_hex() + 
  labs(
    title = "Max Temperature vs Min Temperature for NY Stations",
    x = "Max Temperature (C)",
    y = "Min Temperature (C)",
    caption = "Data from the New York NOAA weather stations") 


snowfall_plot <- ny_noaa_df  %>% 
  mutate(snow = snow_cm *10) %>%
  filter((snow > 0) & (snow < 100)) %>%
  ggplot(aes(x = as.character(year), y = (snow))) + 
  geom_boxplot() + 
  labs(
    title = "Snowfall Across Years (Greater than 0 and Less than 100 mm)",
    x = "Year",
    y = "Snowfall (mm)",
    caption = "Data from the New York NOAA weather stations")  +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))

tmax_vs_tmin_plot / snowfall_plot

```
In the first graph the average max temperature and the average min temperature for many stations tend to be the same/similar.  There are many stations that recorded an average max temperature of around 30 and an average minimum temperature of around 30.  In the second graph, the distribution of snowfall for each year tends to be similar except for a few years.  In 1998, 2006, and 2020 the 3rd quartiles are lower than the rest of the years.









